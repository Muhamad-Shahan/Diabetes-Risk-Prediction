# -*- coding: utf-8 -*-
"""diabetes_model.pkl

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mVCUPQAaMZ-aYO3n7yEYfwzIGrXpgYs9
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from imblearn.combine import SMOTEENN
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

data=pd.read_csv("/content/diabetes_prediction_dataset.csv")

data.head(3)
#data.tail(5)

data.shape

data.columns

data.info()

data.describe()

data.isnull().sum()

data['smoking_history'].unique()

# 1. One-Hot Encoding for 'gender' column
data = data.rename(columns={'gender_Male': 'gender'})#no order involve
data = pd.get_dummies(data, columns=['gender'], drop_first=True)


# 2. Label Encoding for 'smoking_history' column
encoder = LabelEncoder()
data['smoking_history'] = encoder.fit_transform(data['smoking_history'])

data.info()

data.head()

data['bmi'].min()

data.duplicated().sum()

data.drop_duplicates(inplace=True)

data.duplicated().sum()

data['diabetes'].nunique()

class_counts=data['diabetes'].value_counts()

print(class_counts)

from imblearn.combine import SMOTEENN

X = data.drop(columns=['diabetes'])
y = data['diabetes']

# ðŸ“Œ Visualizing Original Class Distribution
plt.figure(figsize=(8, 4))
sns.countplot(x=y, palette="viridis")
plt.title("Class Distribution Before SMOTEENN")
plt.xlabel("Class")
plt.ylabel("Count")
plt.show()

# ðŸ“Œ Apply SMOTEENN
smote_enn = SMOTEENN(sampling_strategy=1.0, random_state=42)
X_resampled, y_resampled = smote_enn.fit_resample(X, y)

# ðŸ“Œ Visualizing Class Distribution After SMOTEENN
plt.figure(figsize=(8, 4))
sns.countplot(x=y_resampled, palette="viridis")
plt.title("Class Distribution After SMOTEENN")
plt.xlabel("Class")
plt.ylabel("Count")
plt.show()

# ðŸ“Œ Print new class distribution
print(pd.Series(y_resampled).value_counts())

correlation=data.corr()['diabetes']
correlation

plt.figure(figsize=(8, 6))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title("Feature Correlation Heatmap")
plt.show()

from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import pandas as pd

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)

# Define Naive Bayes models
models = {
    "Gaussian Naive Bayes": GaussianNB(),
    "Multinomial Naive Bayes": MultinomialNB(),
    "Bernoulli Naive Bayes": BernoulliNB()
}

results = []
for name, model in models.items():
    model.fit(X_train, y_train)  # Train model
    y_pred = model.predict(X_test)  # Predict labels

    # Some models do not support predict_proba, handling it accordingly
    if hasattr(model, "predict_proba"):
        y_prob = model.predict_proba(X_test)[:, 1]  # Get probabilities for AUC-ROC
        auc = roc_auc_score(y_test, y_prob)
    else:
        auc = None  # If not applicable

    # Compute performance metrics
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    # Store results
    results.append({
        "Model": name,
        "Accuracy": accuracy,
        "Precision": precision,
        "Recall": recall,
        "F1-Score": f1,
    })

# Convert results to DataFrame
results_df = pd.DataFrame(results).sort_values(by="F1-Score", ascending=False)

# Display results
print(results_df)

# Set figure size
plt.figure(figsize=(12, 6))

# Melt DataFrame for visualization
df_melted = results_df.melt(id_vars="Model", var_name="Metric", value_name="Score")

# Plot performance metrics
sns.barplot(x="Score", y="Model", hue="Metric", data=df_melted, palette="viridis")

# Add title and labels
plt.title("Classification Model Performance Comparison")
plt.xlabel("Score")
plt.ylabel("Model")
plt.legend(loc="lower right")
plt.show()

import pandas as pd
import pickle
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score

# 1. Load Data
# Make sure you uploaded the csv to Colab files on the left!
df = pd.read_csv('/content/diabetes_prediction_dataset.csv')

# 2. Preprocessing
le_gender = LabelEncoder()
df['gender'] = le_gender.fit_transform(df['gender'])

le_smoking = LabelEncoder()
df['smoking_history'] = le_smoking.fit_transform(df['smoking_history'])

# Define Features and Target
X = df[['gender', 'age', 'hypertension', 'heart_disease', 'smoking_history', 'bmi', 'HbA1c_level', 'blood_glucose_level']]
y = df['diabetes']

# 3. Train Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 4. Train Model
model = GaussianNB()
model.fit(X_train, y_train)

# 5. Evaluate
y_pred = model.predict(X_test)
print(f"Model Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%")

# 6. Save the Model and Encoders
data_to_save = {
    "model": model,
    "le_gender": le_gender,
    "le_smoking": le_smoking
}

# Saving directly to the root folder so it's easy to find
with open('diabetes_model.pkl', 'wb') as f:
    pickle.dump(data_to_save, f)

print("SUCCESS! 'diabetes_model.pkl' has been created.")

